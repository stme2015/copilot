# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XTAm1--TengkkAm9YerSXKOP97mHM6PX
"""

from flask import Flask, request, jsonify
from transformers import AutoTokenizer, AutoModelForCausalLM

app = Flask(__name__)

# Load the fine-tuned model and tokenizer
tokenizer = AutoTokenizer.from_pretrained('model/codegen-350M-mono-finetuned1')
model = AutoModelForCausalLM.from_pretrained('model/codegen-350M-mono-finetuned1')

@app.route('/complete', methods=['POST'])
def complete_code():
  data = request.json
  print(f"Received data: {data}")  # Log the received data
  partial_code = data.get('text', '') #example: def find_maximum(numbers):
  inputs = tokenizer(partial_code, return_tensors="pt")
  # Generate completion\\
  outputs = model.generate(inputs['input_ids'], max_length=150, num_return_sequences=1, temperature=0.4) #tempeature:for more predictable and deterministic output.
  # Decode and send response
  completion = tokenizer.decode(outputs[0], skip_special_tokens=True)

  if completion.startswith(partial_code):
    completion = '\t' + completion[len(partial_code):].strip()

  return jsonify({'completion': completion})

if __name__ == '__main__':
  app.run(port=5000)

